<!DOCTYPE html>
<html>
    <head>
        <title>Artificial Intelligence</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="../styles/styles.css">
    </head>
    <body>
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="../index.html">
            <img src="../assets/logo.PNG" width="30" height="30" alt="">
            Home
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav">
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                      Search Algorithms
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                      <a class="dropdown-item" href="../search/search.html">Intro</a>
                        <a class="dropdown-item" href="../search/bfs.html">BFS</a>
                        <a class="dropdown-item" href="../search/dfs.html">DFS</a>
                        <a class="dropdown-item" href="../search/asearch.html">A* Search</a>
                    </div>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Neural Networks
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                        <a class="dropdown-item" href="./network.html">Intro</a>
                        <a class="dropdown-item" href="./MLP.html">Simple MLP</a>
                        <a class="dropdown-item" href="./CNN.html">CNNs</a>
                        <a class="dropdown-item" href="./RNN.html">RNNs</a>
                        <a class="dropdown-item" href="./GAN.html">GANs</a>
                    </div>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="#">Reinforcement Learning <span class="sr-only">(current)</span></a>
                </li>
            </ul>
          </div>
      </nav>
        <h1>Introduction to MultiLayer Perceptrons</h1>
        <div>
            <p>
                A multilayer perceptron (MLP) is a deep, artificial neural network. 
                It is composed of more than one perceptron. 
                They are composed of an input layer to receive the signal, an output layer that makes a decision or prediction about the input, 
                and in between those two, an arbitrary number of hidden layers that are the true computational engine of the MLP. 
                MLPs with one hidden layer are capable of approximating any continuous function.
                <img src="../assets/networks/mlp.jpg" class="center" height = 400>
            </p>
            <p>
                Multilayer perceptrons are often applied to supervised learning problems: 
                they train on a set of input-output pairs and learn to model the correlation (or dependencies) between those inputs and outputs. 
                Training involves adjusting the parameters, or the weights and biases, of the model in order to minimize error. 
                Backpropagation is used to make those weigh and bias adjustments relative to the error, and the error itself can be measured in a variety of ways, including by root mean squared error (RMSE).
            </p>
        </div>
        <div>
            <h2>Training the Model-</h2>
            <P>
                There are basically three steps in the training of the model.
                <ol class = "listobject">
                    <li>Forward pass</li>
                    <li>Calculate error or loss</li>
                    <li>Backward pass</li>
                </ol>
            </P>
        </div>
        <div>
            <h2>1. Forward Pass</h2>
            <p>
                In this step of training the model, we just pass the input to model and multiply with weights and add bias 
                at every layer and find the calculated output of the model.
                <img src="../assets/networks/mlpforward.png" class="center">
            </p>
        </div>
        <div>
            <h2>2. Loss Calculation</h2>
            <p>
                When we pass the data instance(or one example) we will get some output from the model that is called Predicted output(pred_out) 
                and we have the label with the data that is real output or expected output(Expect_out). 
                Based upon these both we calculate the loss that we have to backpropagate(using Backpropagation algorithm). 
                There is various Loss Function that we use based on our output and requirement.
                <img src="../assets/networks/mlploss.jpeg" class="center">
            </p>
        </div>
        <div>
            <h2>3. Backward Pass</h2>
            <p>
                After calculating the loss, we backpropagate the loss and updates the weights of the model by using gradient. 
                This is the main step in the training of the model. In this step, weights will adjust according to the gradient flow in that direction. 
                For Depth understanding of the Backpropagation algorithm check this nice blog by Andrej Karpathy
                <a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" style="text-decoration: underline;" target="_blank"> 
                    here.
                </a>
                <img src="../assets/networks/mlpback.png" class="center" height=300>
            </p>
        </div>
        <div>
            <p>
                These process are repeated over and over until the loss is made to minimum.
            </p>
            <p>
                For better understanding of MLPs and the Math behind it along eith the code,
                check out the jupyter notebook  
                <a href="https://github.com/crypto-code/Math-of-Neural-Networks/blob/master/1.%20Multi-Layer%20Perceptron.ipynb" style="text-decoration: underline;" target="_blank"> 
                    here.
                </a>
            </p>
        </div>
        <footer class="footer">
            <div class="footer">
                <span>Author: Atin Sakkeer Hussain</span>
            </div>
        </footer>
    </body>
</html>