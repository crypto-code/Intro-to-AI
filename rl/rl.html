<!DOCTYPE html>
<html>
    <head>
        <title>Artificial Intelligence</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <!-- Bootstrap CSS -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="../styles/styles.css">
    </head>
    <body>
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
            <a class="navbar-brand" href="../index.html">
                <img src="../assets/logo.PNG" width="30" height="30" alt="">
                Home
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
              </button>
              <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav">
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                          Search Algorithms
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                            <a class="dropdown-item" href="../search/search.html">Intro</a>
                            <a class="dropdown-item" href="../search/bfs.html">BFS</a>
                            <a class="dropdown-item" href="../search/dfs.html">DFS</a>
                            <a class="dropdown-item" href="../search/asearch.html">A* Search</a>
                        </div>
                    </li>
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                            Neural Networks
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                            <a class="dropdown-item" href="../networks/network.html">Intro</a>
                            <a class="dropdown-item" href="../networks/MLP.html">Simple MLP</a>
                            <a class="dropdown-item" href="../networks/CNN.html">CNNs</a>
                            <a class="dropdown-item" href="../networks/RNN.html">RNNs</a>
                            <a class="dropdown-item" href="../networks/GAN.html">GANs</a>
                        </div>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="./rl.html">Reinforcement Learning <span class="sr-only">(current)</span></a>
                    </li>
                </ul>
              </div>
          </nav>
        <h1>Introduction to Reinforcement Learning</h1>
        <div>
            <p>
                Reinforcement learning in formal terms is a method of machine learning wherein the software agent learns to perform certain actions in an environment which lead it to maximum reward. 
                It does so by exploration and exploitation of knowledge it learns by repeated trials of maximizing the reward.
            </p>
            <p>
                One can conclude that while supervised learning predicts continuous ranged values or discrete labels/classes based on the training it receives from examples with provided labels or values. 
                Unsupervised learning tries to club together samples based on their similarity and determine discrete clusters.
            </p>
            <p>
                Reinforcement learning on the other hand, which is a subset of Unsupervised learning, performs learning very differently. 
                It takes up the method of "cause and effect".
            </p>
        </div>
        <div>
            <h2>Intuition to Reinforcement Learning</h2>
            <p>
                Let us try to understand the previously stated formal definition by means of an example -
            </p>
            <p>
                Imagine you are supposed to cross an unknown field in the middle of a pitch black night without a torch. 
                There can be pits and stones in the field, the position of those are unfamiliar to you. 
                There's a simple rule - if you fall into a hole or hit a rock, you must start again from your initial point.
                <ul class="listobject">
                    <li>
                        You start walking forward blindly, only counting the number of steps you take. 
                        After x steps, you fall into a pit. Your reward was x points since you walked that many steps.
                    </li>
                    <li>
                        You start again from your initial position, but after x steps, you take a detour either left/right and again move forward. 
                        You hit a stone after y steps. This time your reward was y which is greater than x. 
                        You decide to take this path again but with more caution.
                    </li>
                    <li>
                        When you start again, you make a detour after x steps, another after y steps and manage to fall into another pit after z steps. 
                        This time the reward was z points which was greater than y, and you decide that this is a good path to take again.
                    </li>
                    <li>
                        You restart again, make the detours after x, y and z steps to reach the other side of the field. 
                        Thus, you've learned to cross the field without the need of light.
                    </li>
                </ul>
            </p>
        </div>
        <div>
            <h2>Basic Concept and Terminology</h2>
            <h3>Insight</h3>
            <p>
                In the above example, you are the agent who is trying to walk across the field, which is the environment. 
                Walking is the action the agent performs on the environment. The distance the agent walks acts as the reward. 
                The agent tries to perform the action in such a way that the reward maximizes. 
                This is how Reinforcement Learning works in a nutshell. The following figure puts it into a simple diagram -
                <img src="../assets/rl/eg.png" class="center" height = 400>
            </p>
            <p>
                And in the proper technical terms, and generalizing to fit more examples into it, the diagram becomes -
                <img src="../assets/rl/geneg.png" class="center" height = 400>
            </p>
            <h3>Terminology</h3>
            <p>
                Some important terms related to reinforcement learning are
                <ul class="listobject">
                    <li>
                        <b>Agent: </b>a hypothetical entity which performs actions in an environment to gain some reward.
                    </li>
                    <li>
                        <b>Action (a): </b>All the possible moves that the agent can take.
                    </li>
                    <li>
                        <b>Environment (e): </b>A scenario the agent has to face.
                    </li>
                    <li>
                        <b>State (s): </b>Current situation returned by the environment.
                    </li>
                    <li>
                        <b>Reward (R): </b>An immediate return sent back from the environment to evaluate the last action by the agent.
                    </li>
                    <li>
                        <b>Policy (π): </b>The strategy that the agent employs to determine next action based on the current state.
                    </li>
                    <li>
                        <b>Value (V): </b>The expected long-term return with discount, as opposed to the short-term reward R. Vπ(s), is defined as the expected long-term return of the current state s under policy π.
                    </li>
                    <li>
                        <b>Q-value or action-value (Q):</b> Q-value is similar to Value, except that it takes an extra parameter, the current action a. Qπ(s, a) refers to the long-term return of the current state s, taking action a under policy π.
                    </li>
                </ul>
            </p>
        </div>
        <footer class="footer">
            <div class="footer">
                <span>Author: Atin Sakkeer Hussain</span>
            </div>
        </footer>
    </body>
</html>